{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKxGqf9sbg6T",
        "outputId": "3b7ef464-d2aa-4b3f-96a5-5ea4cc9620fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.23.5)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2287620 sha256=ca4d86aeae3b1abf754fc03e1b0f04a97db379261fd0f93d5e642907acbc42c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy-CPzCccRYZ",
        "outputId": "ca6b8e3e-3db3-4954-cf1a-0de4eacd2e54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "43iAgq9bbMR-"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.auto import tqdm\n",
        "import hnswlib\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rDQz63yFcPIp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_all_data(all_data,scores,k):\n",
        "    formatted_dict = []\n",
        "    n=len(all_data)\n",
        "    for i in range(n):\n",
        "        temp = {}\n",
        "        query = all_data[i]['input']\n",
        "        ndocs = len(all_data[i]['profile'])\n",
        "        docs = [all_data[i]['profile'][j]['text'] for j in range(ndocs)]\n",
        "        title = [all_data[i]['profile'][j]['title'] for j in range(ndocs)]\n",
        "        res = sorted(list(zip(docs,title,scores)),key = lambda x:x[2],reverse=True)\n",
        "        res = res[:min(k,ndocs)]\n",
        "        temp['query'] = query\n",
        "        temp['docs'] = [res[i][0] for i in range(min(k,ndocs))]\n",
        "        temp['titles']=[res[i][1] for i in range(min(k,ndocs))]\n",
        "        temp['scores'] = [res[i][2] for i in range(min(k,ndocs))]\n",
        "\n",
        "        formatted_dict.append(temp)\n",
        "    return formatted_dict\n",
        "def write_json(dictionary, file):\n",
        "    json_object = json.dumps(dictionary, indent=4)\n",
        "    with open(file, \"w\") as outfile:\n",
        "        outfile.write(json_object)\n",
        "    return\n",
        "def get_top_k_aip(query,docs,titles,scores,k):\n",
        "    res = sorted(list(zip(docs,titles,scores)),key = lambda x:x[2],reverse=True)\n",
        "    aip = \"\"\n",
        "    for i in range(min(k,len(scores))):\n",
        "        ppep = '\"'+res[i][1]+'\" is the title for \"'+ res[i][0] +'\", and '\n",
        "        aip +=ppep\n",
        "    aip = aip[:-6] + \".\"+query\n",
        "    return aip\n",
        "def get_all_data(filename):\n",
        "    all_data = []\n",
        "    with open(filename, 'r') as file:\n",
        "        json_objects = ijson.items(file, 'item')\n",
        "        for data in json_objects:\n",
        "            all_data.append(data)\n",
        "    return all_data\n",
        "def fwrite(output,filename):\n",
        "    f = open(filename,'w+')\n",
        "    f.write(str(output))\n",
        "    f.close()\n",
        "    return\n",
        "\n",
        "def format_aips(aipfile,outputsfile):\n",
        "    f = open(aipfile,\"r\")\n",
        "    print(aipfile)\n",
        "    aip = eval(f.read())\n",
        "    f2 = open(outputsfile)\n",
        "    y_true = json.load(f2)\n",
        "    y_true = y_true[\"golds\"]\n",
        "    y_true = [i['output'] for i in y_true]\n",
        "\n",
        "    llm_data = pd.DataFrame({\n",
        "        'text':aip,\n",
        "        'label':y_true\n",
        "    })\n",
        "    op_name = str(aipfile).split('.txt')[0]+\"_llm_input.csv\"\n",
        "    llm_data.to_csv(op_name)\n",
        "    return"
      ],
      "metadata": {
        "id": "MiauquKTbkv6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hnsw(all_data,vectorizer):\n",
        "    aip = []\n",
        "    all_scores = []\n",
        "    count=0\n",
        "    for instance in all_data:\n",
        "        query = instance['input']\n",
        "        docs = [instance['profile'][i]['text'] for i in range(len(instance['profile']))]\n",
        "        titles = [instance['profile'][i]['title'] for i in range(len(instance['profile']))]\n",
        "        document_vectors = vectorizer.fit_transform(docs).toarray()\n",
        "        dim = document_vectors.shape[1]\n",
        "        num_elements = len(docs)\n",
        "        index = hnswlib.Index(space='cosine', dim=dim)\n",
        "        index.init_index(max_elements=num_elements, ef_construction=200, M=20)\n",
        "        index.add_items(document_vectors)\n",
        "        #decide how much ef\n",
        "        index.set_ef(200)\n",
        "        query_vector = vectorizer.transform([query]).toarray()[0]\n",
        "        max_score_index, distances = index.knn_query(query_vector, k=num_elements)\n",
        "        max_score_index = max_score_index.tolist()\n",
        "        distances = distances.tolist()\n",
        "        res = sorted(list(zip(max_score_index[0],distances[0])))\n",
        "        scores = [1-res[i][1] for i in range(len(res))]\n",
        "        all_scores.append(scores)\n",
        "        title = titles[max_score_index[0][0]]\n",
        "        op = '\"'+title+'\" is the title for \"'+ docs[max_score_index[0][0]] +'\".'+query\n",
        "        aip.append(op)\n",
        "        count+=1\n",
        "        print(count)\n",
        "    return aip,all_scores"
      ],
      "metadata": {
        "id": "22ceX_WhbcCp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble(all_data,models):\n",
        "    n = len(all_data)\n",
        "    aip = []\n",
        "    num_models = len(models)\n",
        "    all_overall = []\n",
        "    for i in range(n):\n",
        "        query = all_data[i]['input']\n",
        "        title = [all_data[i]['profile'][j]['title'] for j in range(len(all_data[i]['profile']))]\n",
        "        docs  = [all_data[i]['profile'][j]['text'] for j in range(len(all_data[i]['profile']))]\n",
        "        ndocs = len(docs)\n",
        "        overall_scores = [0 for i in range(ndocs)]\n",
        "        for j in range(num_models):\n",
        "            overall_scores = [overall_scores[k]+models[j][i][k] for k in range(ndocs)]\n",
        "        overall_scores = [(1/num_models)*overall_scores[k] for k in range(ndocs)]\n",
        "        aip.append(get_top_k_aip(query,docs,title,overall_scores,5))\n",
        "        all_overall.append(overall_scores)\n",
        "        #max_score_index = overall_scores.index(max(overall_scores))\n",
        "        #op = '\"'+txt +'\"'+docs[max_score_index]+'\" is \"'+categories[max_score_index]+'\"\".'+all_data[i]['input']\n",
        "        #aip.append(op)\n",
        "    return aip, all_overall"
      ],
      "metadata": {
        "id": "m7L7q2KNbvo5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert(all_data, tokenizer, model):\n",
        "    aip = []\n",
        "    all_scores=[]\n",
        "    progress_bar = tqdm(range(101))\n",
        "    for instance in all_data:\n",
        "        query = instance['input']\n",
        "        docs = [instance['profile'][i]['text'] for i in range(len(instance['profile']))]\n",
        "        title =[instance['profile'][i]['title'] for i in range(len(instance['profile']))]\n",
        "        document_tokens = tokenizer.batch_encode_plus(docs, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "        query_tokens = tokenizer.encode_plus(query, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "        document_embeddings = model(**document_tokens).last_hidden_state.mean(dim=1)  # Average pooling over tokens\n",
        "        query_embedding = model(**query_tokens).last_hidden_state.mean(dim=1).squeeze()\n",
        "        similarities = cosine_similarity(query_embedding.reshape(1, -1).detach().cpu().numpy(), document_embeddings.detach().cpu().numpy()).squeeze()\n",
        "        progress_bar.update(1)\n",
        "        ranking = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
        "        #print(ranking)\n",
        "        max_score_index = ranking[0][0]\n",
        "        op = '\"'+title[max_score_index]+'\" is the title fxor \"'+ docs[max_score_index] +'\".'+query\n",
        "        aip.append(op)\n",
        "        ranking = sorted(ranking)\n",
        "        scores = [ranking[i][1] for i in range(len(ranking))]\n",
        "        #print(\"SCORES\",ranking,scores)\n",
        "        all_scores.append(scores)\n",
        "    return aip, all_scores"
      ],
      "metadata": {
        "id": "HB123tupb_6K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_model(all_data):\n",
        "    aip=[]\n",
        "    all_scores = []\n",
        "    #ppep format \"Pi[title]\" is the title for \"Pi[text]\"\n",
        "    for i in range(len(all_data)):\n",
        "        query = all_data[i]['input']\n",
        "        docs = [all_data[i]['profile'][j]['text'] for j in range(len(all_data[i]['profile'])) ]\n",
        "        tokenized_docs = [doc.split() for doc in docs]\n",
        "        title = [all_data[i]['profile'][j]['title'] for j in range(len(all_data[i]['profile'])) ]\n",
        "        bm25 = BM25Okapi(tokenized_docs)\n",
        "        scores = bm25.get_scores(query.split())\n",
        "        #min max normalization\n",
        "        min_score = min(scores)\n",
        "        max_score = max(scores)\n",
        "        if max_score == min_score:\n",
        "            scores = [1.0 for i in range(len(scores))]\n",
        "        else:\n",
        "            scores = [(score- min_score)/(max_score-min_score)  for score in scores]\n",
        "        all_scores.append(scores)\n",
        "        max_score_index = np.argmax(scores)\n",
        "\n",
        "        #ppep format \"Pi[title]\" is the title for \"Pi[text]\"\n",
        "        op = '\"'+title[max_score_index]+'\" is the title for \"'+ docs[max_score_index] +'\".'+query\n",
        "        aip.append(op)\n",
        "    return aip,all_scores"
      ],
      "metadata": {
        "id": "WYcL74fdcIQM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_output(filename):\n",
        "    f = open(filename,\"r\")\n",
        "    scores= f.read()\n",
        "    scores = ast.literal_eval(scores)\n",
        "    #print(\"LEN\",len(scores))\n",
        "    return scores"
      ],
      "metadata": {
        "id": "Gch7FwYjdLDW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file = 'dev_questions.json'\n",
        "output_file = 'dev_outputs.json'\n",
        "all_data = get_all_data(file)"
      ],
      "metadata": {
        "id": "E25MJIQqchCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "bm25_s = read_output('bm25/train/bm25_scores_train.txt')\n",
        "bert_s = read_output('bert/train/bert_scores_train.txt')\n",
        "hnsw_s = read_output('hnsw/train/hnsw_scores_train.txt')"
      ],
      "metadata": {
        "id": "Bl0tBkbmdjaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [[bm25_s,hnsw_s,bert_s],[bm25_s,bert_s],[bert_s,hnsw_s],[bm25_s,hnsw_s]]\n",
        "#models = [[bm25_s,hnsw_s]]\n",
        "#names = ['bm25_hnsw_dev']\n",
        "names = ['bm25_hnsw_bert_dev','bm25_bert_dev','bert_hnsw_dev','bm25_hnsw_dev']\n",
        "for i in range(len(models)):\n",
        "#print(len(models[0]))\n",
        "    aip,overall_scores  = ensemble(all_data,models[i])\n",
        "    fname = 'ensemble/aip/'+names[i]+'_aip_100.txt'\n",
        "    fwrite(aip,fname)\n",
        "    fwrite(overall_scores,'ensemble/scores/'+names[i]+'_scores_100.txt')\n",
        "    format_aips(fname,'dev_outputs.json')"
      ],
      "metadata": {
        "id": "TXzs6wtOdUNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}